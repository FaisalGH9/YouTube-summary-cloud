# ðŸŽ® Watch Less, Learn More â€” Multimodal AI Chatbot for YouTube Video QA

## ðŸ“Œ Overview

**Watch Less, Learn More** is an advanced multimodal AI-powered web application that transforms YouTube videos into structured, searchable, and interactive knowledge. Designed with educators, researchers, and curious learners in mind, the system leverages state-of-the-art AI to transcribe, summarize, and answer questions about videos â€” all through a smart and intuitive interface.

âœ… Built with **LangChain**, **OpenAI**, **Whisper**, **FAISS/ChromaDB**, and **LangSmith**
âœ… Designed for **text, audio, and multilingual interaction**
âœ… Evaluated with **LangSmith Tracing Dashboard** for performance, latency, and error analysis

---

## ðŸŽ¯ Project Objectives

* Convert **YouTube video/audio** into text using speech-to-text (Whisper)
* Generate **structured summaries** with Table of Contents using OpenAI APIs
* Provide **real-time Q\&A interaction** via a chatbot powered by LangChain Agents
* Allow **multilingual translation** of summaries and transcripts
* Enable **comprehension quizzes** to evaluate user understanding
* Track performance and trace responses using **LangSmith**

---

## ðŸ§  Features

| Feature                 | Description                                                         |
| ----------------------- | ------------------------------------------------------------------- |
| ðŸŽ¤ Speech Recognition   | Transcribe videos using Whisper (for accuracy over auto-captioning) |
| ðŸ§ž Summary Generator    | 3-tier summaries (Detailed, Medium, Short) with Table of Contents   |
| ðŸ¤– Chatbot (Q\&A)       | LangChain agent answers questions based on transcript context       |
| ðŸŒ Multilingual Support | Translate summaries/transcripts to Arabic, French, German, Spanish  |
| ðŸ§ª LangSmith Evaluation | Monitor errors, latency, and feedback for continuous improvements   |
| ðŸ“š Comprehension Quiz   | Auto-generated quiz to test user knowledge                          |
| ðŸ“… Export Options       | Download summaries as PDF or TXT                                    |
| ðŸ”— Social Sharing       | Share summaries directly on LinkedIn, WhatsApp, or X                |

---

## ðŸ§± Tech Stack

| Category             | Tool/Library                      |
| -------------------- | --------------------------------- |
| ðŸ§  LLM               | OpenAI GPT-4 / GPT-3.5 Turbo      |
| ðŸ—£ï¸ Speech-to-Text   | OpenAI Whisper                    |
| ðŸ”— Framework         | LangChain (Agents, Tools, Chains) |
| ðŸ” Vector DB         | ChromaDB or FAISS                 |
| ðŸ“¦ Deployment        | Streamlit                         |
| ðŸ“Š Evaluation        | LangSmith                         |
| ðŸ§ª Environment Mgmt  | Python 3.10, .env via dotenv      |
| ðŸ“š Document Handling | FPDF, BeautifulSoup               |
| ðŸŽ¥ Video Processing  | moviepy, yt\_dlp                  |

---

## ðŸš€ Project Structure

```
ðŸ“ my_project/
â”œâ”€â”€ app.py               # Main Streamlit application
â”œâ”€â”€ qa_agent.py          # LangChain Agent and QA logic
â”œâ”€â”€ transcriber.py       # Whisper transcription handler
â”œâ”€â”€ summarizer.py        # Summary generation with TOC
â”œâ”€â”€ vector_store.py      # Chunking & vector DB storage
â”œâ”€â”€ utils.py             # Helper functions (e.g., video ID extraction)
â”œâ”€â”€ requirements.txt     # Dependencies list
â”œâ”€â”€ .env                 # API keys and environment variables
â”œâ”€â”€ README.md            # This file
â””â”€â”€ ðŸ“ downloads/uploads  # Uploaded/downloaded content
```

---

## ðŸ› ï¸ Setup & Installation

1. **Clone the repository**

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

2. **Create and activate virtual environment**

```bash
python -m venv venv
# On Windows
venv\Scripts\activate
# On Mac/Linux
source venv/bin/activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Set your environment variables**

Create a `.env` file:

```env
OPENAI_API_KEY=your_openai_key
LANGCHAIN_API_KEY=your_langsmith_key
```

5. **Run the app**

```bash
streamlit run app.py
```

---

## âœ… Evaluation with LangSmith

LangSmith was integrated to trace agent behavior and evaluate:

| Metric        | Description                              |
| ------------- | ---------------------------------------- |
| ðŸ§  Accuracy   | Ensuring context-aware answers           |
| ðŸ” Error Rate | Logged and traced failed agent responses |
| ðŸ•“ Latency    | P50 and P99 latency recorded             |
| ðŸ§ª Feedback   | Each run is traceable and debuggable     |

Access your dashboard: [LangSmith Traces](https://smith.langchain.com)

---

## ðŸ“¦ Deployment Options

This app can be deployed using:

* âœ… Local Streamlit Deployment *(Recommended for demo)*
* â˜ï¸ Cloud:

  * Streamlit Cloud
  * HuggingFace Spaces *(via Gradio wrapper)*
  * Docker *(via `Dockerfile`)*

---

## ðŸ“š Future Improvements

* ðŸŽ¤ Voice-in/voice-out conversational support
* ðŸ“· Integration of thumbnails and visual grounding
* âš•ï¸ Domain-specific QA modules (e.g., healthcare, legal)
* ðŸ” Use Pinecone for production-grade vector search
* ðŸ§  Fine-tuning summarization and QA for domain accuracy

---

## ðŸ§ª Testing & Evaluation Plan

* âœ… Baseline QA and improved context retrieval
* âœ… Hallucination detection via LangSmith traces
* âœ… Human-AI translation quality comparison
* âœ… Latency and error tracking
* âœ… Memory usage profiling

---

> Developed by **Alhanoof Aljamaan** â€” Powered by OpenAI & LangChain


<!-- google drive video  -->
https://drive.google.com/drive/folders/1d-rrbEN6Yv4q7FJtcbKPeo73U6QdIZvo

<!-- presintion  -->
https://www.canva.com/design/DAGmpo-A99o/jLlnVNfaG3VJ7FRUDXU3wQ/edit?utm_content=DAGmpo-A99o&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton